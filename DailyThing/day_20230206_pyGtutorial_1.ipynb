{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! cat /etc/os-release # OS version\n",
        "! lsb_release -a # OS version\n",
        "! uname -r # Linux kernel version\n",
        "! nvcc --version # CUDA version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQLunyC4eXI-",
        "outputId": "cc1ce35f-1045-42b0-8264-2021aa61b5a8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"20.04.5 LTS (Focal Fossa)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 20.04.5 LTS\"\n",
            "VERSION_ID=\"20.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=focal\n",
            "UBUNTU_CODENAME=focal\n",
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 20.04.5 LTS\n",
            "Release:\t20.04\n",
            "Codename:\tfocal\n",
            "5.10.147+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok_VE-Zob2Bd",
        "outputId": "b9dd186b-baae-4304-b638-a5160b9c7153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyG\n",
        "! pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cu116.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEH_a-Bhe1iA",
        "outputId": "10ef748b-04eb-4db4-dd06-8fdd6a9b8b45"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.8/dist-packages (0.1.0+pt113cu116)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.8/dist-packages (2.1.0+pt113cu116)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.8/dist-packages (0.6.16+pt113cu116)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.8/dist-packages (1.6.0+pt113cu116)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.8/dist-packages (1.2.1+pt113cu116)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tqdm\n",
        "! pip install japanize-matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhN3Oj8j6xFE",
        "outputId": "5ce913c5-bbe3-4a15-8714-474eb5e547cb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction by Example \n",
        "\n",
        "[This Document](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html)\n",
        "\n",
        "[Install Page](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html)"
      ],
      "metadata": {
        "id": "jeHbs7adjTkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "\n",
        "import torch \n",
        "print(torch.__version__)\n",
        "import torch_geometric\n",
        "print(torch_geometric.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hagKp3USzcI8",
        "outputId": "42b09723-0453-446f-85ce-54efa092c2fd"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I32zH3Sad8vt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def torch_fix_seed(seed=0):\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True\n",
        "\n",
        "SEED=1\n",
        "torch_fix_seed(SEED)"
      ],
      "metadata": {
        "id": "7yB9osHPnoB2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Data handring of Graph\n",
        "\n",
        "-  Graph : a data format for objectcts(Node) and rerations(Edge)\n",
        "- Data Object\n",
        "  - data.x: Node feature matrix with shape [num_nodes, num_node_features]\n",
        "\n",
        " - data.edge_index: Graph connectivity in COO format with shape [2(edge_deg), num_edges] and type torch.long\n",
        "\n",
        " - data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
        "\n",
        " - data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *]\n",
        "\n",
        " - data.pos: Node position matrix with shape [num_nodes, num_dimensions]\n",
        "\n",
        "- "
      ],
      "metadata": {
        "id": "5hnK5mxZcPzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "edge_index = torch.tensor([[0, 1, 1, 2],\n",
        "                           [1, 0, 2, 1]], dtype=torch.long)\n",
        "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "#>>> Data(edge_index=[2, 4], x=[3, 1])\n"
      ],
      "metadata": {
        "id": "ygsbf8mhgjtN"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Data(edge_index=[2, 4], x=[3, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSRztwrCgrmz",
        "outputId": "9811b6cf-958b-4029-e29d-e592870e0e38"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2], edge_index=[2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer data object to GPU.\n",
        "device = torch.device('cuda')\n",
        "data = data.to(device)"
      ],
      "metadata": {
        "id": "uWUGkJ_vg1S3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Data(edge_index=[2, 4], x=[3, 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCwQPmJibVE",
        "outputId": "8e9f2340-a9a7-42c4-e5e7-29d70c9f938e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2], edge_index=[2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kk0af596i0Ik"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## common datasets\n",
        "\n",
        "- [Benchmark data source]( http://graphkernels.cs.tu-dortmund.de )\n"
      ],
      "metadata": {
        "id": "H2KWeB_-i42t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "\n",
        "from torch_geometric.utils import scatter\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "torch_fix_seed(SEED)\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "# dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
        "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "for data in loader:\n",
        "    print(f\"{data=}\")\n",
        "    print(f\"{data.num_graphs=}\")\n",
        "    x = scatter(data.x, data.batch, dim=0, reduce='mean')\n",
        "    print(x.size())\n",
        "    print()\n",
        "\n",
        "# print(dataset)\n",
        "# # ENZYMES(600)\n",
        "# len(dataset)\n",
        "# #>>> 600\n",
        "# print(f\"{dataset.num_classes=}\\t{dataset.num_node_features=}\")\n",
        "# #>>> 6 #>>> 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-hNJPFfjNrG",
        "outputId": "3196671c-aa1c-48f6-8391-a337340da5b4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data=DataBatch(edge_index=[2, 4636], x=[1278, 21], y=[32], batch=[1278], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3634], x=[969, 21], y=[32], batch=[969], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 4018], x=[1070, 21], y=[32], batch=[1070], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3582], x=[932, 21], y=[32], batch=[932], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 4356], x=[1083, 21], y=[32], batch=[1083], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 4158], x=[1063, 21], y=[32], batch=[1063], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 4048], x=[1051, 21], y=[32], batch=[1051], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3878], x=[961, 21], y=[32], batch=[961], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3934], x=[1029, 21], y=[32], batch=[1029], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 4162], x=[1058, 21], y=[32], batch=[1058], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3614], x=[951, 21], y=[32], batch=[951], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3956], x=[1184, 21], y=[32], batch=[1184], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 4388], x=[1169, 21], y=[32], batch=[1169], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3668], x=[924, 21], y=[32], batch=[924], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3622], x=[935, 21], y=[32], batch=[935], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 4008], x=[1076, 21], y=[32], batch=[1076], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3956], x=[1048, 21], y=[32], batch=[1048], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3860], x=[986, 21], y=[32], batch=[986], ptr=[33])\n",
            "data.num_graphs=32\n",
            "torch.Size([32, 21])\n",
            "\n",
            "data=DataBatch(edge_index=[2, 3086], x=[813, 21], y=[24], batch=[813], ptr=[25])\n",
            "data.num_graphs=24\n",
            "torch.Size([24, 21])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Cora()\n",
        "\n",
        "this time, the Data objects holds a label for each node, and additional node-level attributes: train_mask, val_mask and test_mask, where\n",
        "\n",
        "train_mask denotes against which nodes to train (140 nodes),\n",
        "\n",
        "val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes),\n",
        "\n",
        "test_mask denotes against which nodes to test (1000 nodes)."
      ],
      "metadata": {
        "id": "QFqdIcgTqUo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data =  dataset[0]\n",
        "# print(f\"{data=}\")\n",
        "# print(f\"{data.validate()=}\\t{data.is_undirected=}\")"
      ],
      "metadata": {
        "id": "osJLqSu-kxFo"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For TUDatast We can see that the first graph in the dataset contains 37 nodes, each one having 3 features. There are 168/2 = 84 undirected edges and the graph is assigned to exactly one class. In addition, the data object is holding exactly one graph-level target.\n",
        "\n"
      ],
      "metadata": {
        "id": "USCPay6Sl-pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can even use slices, long or bool tensors to split the dataset. E.g., to create a 90/10 train/test split, type:\n",
        "\n"
      ],
      "metadata": {
        "id": "sYROdGMzmWOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch_fix_seed(SEED)\n",
        "# train_test_splitNum = int(len(dataset)/0.9)\n",
        "# dataset_shuffle = dataset.shuffle()\n",
        "# #>>> ENZYMES(600)\n",
        "\n",
        "# train_dataset = dataset_shuffle[:train_test_splitNum]\n",
        "# #>>> ENZYMES(540)\n",
        "# test_dataset = dataset_shuffle[train_test_splitNum:]\n",
        "# #>>> ENZYMES(60)\n",
        "# print(f\"{train_dataset=}\\n{test_dataset=}\")"
      ],
      "metadata": {
        "id": "o7GLORaokX3m"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch_fix_seed(SEED)\n",
        "# perm = torch.randperm(len(dataset))\n",
        "# dataset_perm = dataset[perm]\n",
        "# #>> ENZYMES(600)\n",
        "# print(f\"{(dataset_perm==dataset_shuffle)=}\")"
      ],
      "metadata": {
        "id": "Y8CdV6a2mpYI"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "まじ？？やばくね？"
      ],
      "metadata": {
        "id": "c-E7gCzun8Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "ifzp8Fc6nZJs"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Transforms"
      ],
      "metadata": {
        "id": "JEBhxL1auCpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import ShapeNet\n",
        "\n",
        "# dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'])\n",
        "\n",
        "# dataset[0]\n",
        "# >>> Data(pos=[2518, 3], y=[2518])"
      ],
      "metadata": {
        "id": "t1sueAMVuFse"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can convert the point cloud dataset into a graph dataset by generating nearest neighbor graphs from the point clouds via transforms:\n",
        "\n",
        "In addition, we can use the transform argument to randomly augment a Data object, e.g., translating each node position by a small number:"
      ],
      "metadata": {
        "id": "aUuzg3mfuhCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import ShapeNet\n",
        "\n",
        "dataset = ShapeNet(root='/tmp/ShapeNet', categories=['Airplane'],\n",
        "                  pre_transform=T.KNNGraph(k=6),\n",
        "                  transform=T.RandomJitter(0.01),\n",
        "                   )\n",
        "#NOTE:: The pre_transform is only applied when processing the dataset for the first time.\n",
        "\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDpB8yttuXHq",
        "outputId": "e2522907-71cf-455b-9fdf-cc7aec5538c2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1], edge_index=[2, 15108])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5-Tvhccv4qv"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Methods On Graphs\n",
        "\n"
      ],
      "metadata": {
        "id": "o8QHlL3KwLwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "def train(model,  optimizer, data, ):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  out = model(data)\n",
        "  loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval(model, data):\n",
        "  model.eval()\n",
        "  pred = model(data).argmax(dim=1)\n",
        "  correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
        "  acc = int(correct) / int(data.test_mask.sum())\n",
        "  return acc"
      ],
      "metadata": {
        "id": "nK1SfmXBwXsZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The constructor defines two GCNConv layers which get called in the forward pass of our network. Note that the non-linearity is not integrated in the conv calls and hence needs to be applied afterwards (something which is consistent accross all operators in PyG). Here, we chose to use ReLU as our intermediate non-linearity and finally output a softmax distribution over the number of classes. Let’s train this model on the training nodes for 200 epochs:"
      ],
      "metadata": {
        "id": "83RCvziFwzwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.datasets import Planetoid\n",
        "\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "\n"
      ],
      "metadata": {
        "id": "neOekEBLwTAQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "data = dataset[0].to(device)\n",
        "# criterion = F.nll_loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "MaxEpoch =200\n",
        "\n",
        "for epoch in range(MaxEpoch):\n",
        "    model =train(model,  optimizer, data)\n",
        "acc = eval(model,data)\n",
        "print(f'Accuracy: {acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txb4-Ztow0ws",
        "outputId": "162b863d-1758-4882-9ffa-d970d62e60e6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ひとつのグラフに対して学習しているので精度が高いのは当たり前のように思われる．\n",
        "\n",
        "データセットのデータを流石に変えないと意味ないわ"
      ],
      "metadata": {
        "id": "7XyNFJpFEtIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "data = dataset[0].to(device)\n",
        "\n",
        "# criterion = F.nll_loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "MaxEpoch =200\n",
        "\n",
        "for epoch in range(MaxEpoch):\n",
        "    model =train(model,  optimizer, data)\n",
        "test_data = dataset[-1].to(device)\n",
        "acc = eval(model,test_data)\n",
        "print(f'Accuracy: {acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYXTHp0xE9Gp",
        "outputId": "f1b87e0f-a7bf-42f0-b709-203ba8232da9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "た．．．たけぇ\n",
        "\n",
        "恐れ入ります"
      ],
      "metadata": {
        "id": "YU9RYqRgFmDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pwd\n"
      ],
      "metadata": {
        "id": "SVUFWb8Sxdsb"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ALL Things Up"
      ],
      "metadata": {
        "id": "nqzdd4lLzTem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "! rm -R ../tmp/ShapeNet/processed\n",
        "#NOTE:: The pre_transform is only applied when processing the dataset for the first time."
      ],
      "metadata": {
        "id": "H4qdYg-munNO"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
        "print(dataset)\n",
        "print(dataset[0])\n",
        "print(dataset[0].x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ayon4DiA7FV",
        "outputId": "048b234f-7475-4262-9bfd-eb870b5c7510"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENZYMES(600)\n",
            "Data(edge_index=[2, 168], x=[37, 21], y=[1])\n",
            "tensor([11.0000, 15.8870, 37.7800, -0.5100,  1.7010, 93.9000,  4.0000,  5.0000,\n",
            "         2.0000,  4.0000,  4.0000,  3.0000,  3.0000,  4.0000,  4.0000,  3.0000,\n",
            "         6.0000,  2.0000,  1.0000,  0.0000,  0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "SEED=1\n",
        "torch_fix_seed(SEED)\n",
        "\n",
        "MaxEpoch =200\n",
        "BATCH =34\n",
        "# train : validation : test = 0.8: 0.1: 0.1\n",
        "tr_val_percent =0.8\n",
        "val_te_percent =0.1 \n",
        "\n",
        "# PREPARE DATASET and  DEVICE\n",
        "# dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES', use_node_attr=True)\n",
        "# print(len(dataset))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#SPLIT DATA SET\n",
        "train_val_splitNum = int(len(dataset)*tr_val_percent)\n",
        "val_test_splitNum = int(len(dataset)*(val_te_percent+tr_val_percent))\n",
        "dataset_shuffle = dataset.shuffle()\n",
        "print(f\"{train_val_splitNum=}\\t{val_test_splitNum=}\")\n",
        "\n",
        "# PREPARE DATA SET\n",
        "train_dataset = dataset_shuffle[:train_val_splitNum]\n",
        "val_dataset = dataset_shuffle[train_val_splitNum:val_test_splitNum]\n",
        "test_dataset = dataset_shuffle[val_test_splitNum:]\n",
        "print(f\"{train_dataset=}\\n{val_dataset=}\\n{test_dataset=}\")\n",
        "\n",
        "# PREPARE DATA LOADER\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=True )\n",
        "\n",
        "\n",
        "model = GCN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "# Loss Func : nll Loss\n",
        "\n",
        "acc_val= list()\n",
        "acc_test = list()\n",
        "\n",
        "for epoch in range(MaxEpoch):\n",
        "    dataloader_iterator = iter(val_loader)\n",
        "    for train_data in tqdm(train_loader): \n",
        "        try:\n",
        "            val_data = next(dataloader_iterator)\n",
        "        except StopIteration:\n",
        "            dataloader_iterator = iter(val_loader)\n",
        "            val_data = next(dataloader_iterator)\n",
        "        train_data = train_data.to(device)\n",
        "        val_data = val_data.to(device)\n",
        "\n",
        "        model =train(model,  optimizer, train_data)\n",
        "        # AttributeError: 'GlobalStorage' object has no attribute 'train_mask'\n",
        "        ### そらそう，クラス分類タスクしたいのに，ターゲットのクラスが一つの上に\n",
        "        ### 前回使用したモデルを流用しようとしているため\n",
        "\n",
        "        ### グラフデータのattr属性の意味がわかってない ###\n",
        "\n",
        "        acc = eval(model,val_data)\n",
        "        \n",
        "        acc_val.append(acc)\n",
        "\n",
        "for test_data in tqdm(test_loader):\n",
        "    test_data=test_data.to(device)\n",
        "    acc =eval(model, test_data)\n",
        "    acc_test.append(acc)\n",
        "print(f'VAL Accuracy: {mean(acc_val)}±{stdev(acc_val)}')\n",
        "print(f'TEST Accuracy: {mean(acc_test)}±{stdev(acc_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 995
        },
        "id": "krePjWvDyWeI",
        "outputId": "85029a7c-3625-43d8-aa3d-7d2b96a1182e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_val_splitNum=480\tval_test_splitNum=540\n",
            "train_dataset=ENZYMES(480)\n",
            "val_dataset=ENZYMES(60)\n",
            "test_dataset=ENZYMES(60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/15 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'train_mask'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-e6b2da18310f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-c3c288147669>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \"root folder and try again.\")\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m     65\u001b[0m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oVJBJwnA7FQy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}